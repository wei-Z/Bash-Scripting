# example: using curl and grep to get YoutTube title
curl 'http://www.youtube.com/watch?v=Dd7dQh8u4Hc' -so - | \
    grep -iPo '(?<=<title>)(.*)(?=</title>)'


# the following is output all span string with all the data we need, but we need to cut out some unneeded data
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>'


# next, how to recognize only the data we want …

# trying to use another grep before to get table part

## part I: to get table header
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<thead data-reactid=)(.*)(?=</thead>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>' 

# —improvement: now <span> and </span> is taken off
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<thead data-reactid=)(.*)(?=</thead>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>' | sed -e 's/<[^>]*>//g'

#  add ‘,’ to each output
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<thead data-reactid=)(.*)(?=</thead>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>' | sed -e 's/<[^>]*>//g' | sed 's/$/,/'

# This will put the titles into cvs  as header row
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<thead data-reactid=)(.*)(?=</thead>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>' | sed -e 's/<[^>]*>//g' | sed 's/$/,/' | xargs > file.csv


## part II: to get table content
# the following will give every span… not exactly what I need
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<tr class=)(.*)(?=</tr>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>'

# this will give the td content only which works
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<tr class=\"BdT Bdc\(\$lightGray\) Ta\(end\) Fz\(s\)\")(.*)(?=</tr>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>'
# this will take off <span> and </span>
curl 'https://in.finance.yahoo.com/quote/GOOG/history?ltr=1' -so - |grep -iPo '(?<=<tr class=\"BdT Bdc\(\$lightGray\) Ta\(end\) Fz\(s\)\")(.*)(?=</tr>)' | grep -iPo '<span data-reactid="[1-9][0-9]*">(.*?)</span>' | sed -e 's/<[^>]*>//g'


# awk, pr: split input
1. 
https://stackoverflow.com/questions/14519372/put-every-n-rows-of-input-into-a-new-column
2.
https://stackoverflow.com/questions/8714355/bash-turning-multi-line-string-into-single-comma-separated
3.
https://stackoverflow.com/questions/8522851/concise-and-portable-join-on-the-unix-command-line
4.
https://stackoverflow.com/questions/39572696/group-every-nth-line-command-output-in-a-csv-format
5.
https://stackoverflow.com/questions/27388136/send-the-unix-output-to-a-csv-file
6.
https://stackoverflow.com/questions/28700492/bash-script-to-generate-csv-file-from-text


# might help
—bash output to csv columns
https://stackoverflow.com/questions/25788520/bash-output-to-csv-columns
http://www.linuxquestions.org/questions/linux-newbie-8/howto-ls-output-to-csv-format-808545/
https://stackoverflow.com/questions/4935278/concatenate-a-string-to-the-end-of-every-output-line-in-bash-csh


—good source for everything
http://www.tldp.org/LDP/abs/html/textproc.html
— AWK
http://www.grymoire.com/Unix/Awk.html#uh-18


